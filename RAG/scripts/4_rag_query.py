from dotenv import load_dotenv
from azure.core.credentials import AzureKeyCredential
from azure.search.documents import SearchClient
from openai import AzureOpenAI
import os
import gradio as gr
import time
import requests
import json


# âœ… í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()
search_endpoint = os.getenv("AZURE_SEARCH_ENDPOINT")
search_key = os.getenv("AZURE_SEARCH_KEY")
openai_endpoint = os.getenv("AZURE_OPENAI_ENDPOINT")
openai_key = os.getenv("AZURE_OPENAI_KEY")
openai_api_version = os.getenv("OPENAI_API_VERSION")
embedding_model = os.getenv("AZURE_EMBEDDING_DEPLOYMENT")
chat_model = os.getenv("AZURE_OPENAI_DEPLOYMENT_NAME")
index_name = "my-hybrid-index2"

# âœ… AzureOpenAI í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
client = AzureOpenAI(
    api_key=openai_key,
    api_version=openai_api_version,
    azure_endpoint=openai_endpoint
)

# âœ… ì‚¬ìš©ì ì§ˆë¬¸ â†’ ì„ë² ë”© ë²¡í„°
def get_query_embedding(query_text):
    try:
        response = client.embeddings.create(
            model=embedding_model,
            input=[query_text]
        )
        return response.data[0].embedding
    except Exception as e:
        print(f"âŒ ì„ë² ë”© ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

# âœ… Azure Cognitive Search â†’ ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰

def search_similar_docs(query_vector, top_k=10):
    url = f"{search_endpoint}/indexes/{index_name}/docs/search?api-version=2024-07-01"
    headers = {
        "Content-Type": "application/json",
        "api-key": search_key
    }
    payload = {
        "search": "",
        "top": top_k,
        "vectorQueries": [{"vector": query_vector, "fields": "embedding", "k": top_k, "kind": "vector"}],
        "select": "content, title, movements" 
    }
    try:
        response = requests.post(url, headers=headers, json=payload)
        response.raise_for_status()
        results = response.json()["value"]
        contexts_with_titles = [{"content": doc["content"], "title": doc.get("title", "ì œëª© ì—†ìŒ")} for doc in results if doc and "content" in doc and doc["content"] is not None]
        return contexts_with_titles
    except requests.exceptions.RequestException as e:
        print(f"âŒ REST API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        if response is not None:
            print(f"âŒ ì‘ë‹µ ë‚´ìš©: {response.text}")
        return []

# âœ… GPT ì‘ë‹µ ìƒì„±
def generate_response(user_query, contexts_with_titles):
    context_contents = [item["content"] for item in contexts_with_titles]
    prompt = f"""ë‹¤ìŒ ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µí•˜ì„¸ìš”.
ë¬¸ì„œ:
{"".join(context_contents)}

ì§ˆë¬¸: {user_query}
ë‹µë³€:"""

    chat_response = client.chat.completions.create(
        model=chat_model,
        messages=[
            {"role": "system", "content": '''ë‹¹ì‹ ì€ ì¸ë°”ë”” ê²€ì‚¬ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ ê°œì¸ ë§ì¶¤í˜• ê·¼ë ¥ìš´ë™ í”„ë¡œê·¸ë¨ì„ ì„¤ê³„í•˜ëŠ” **ì „ë¬¸ í¼ìŠ¤ë„ íŠ¸ë ˆì´ë„ˆ AI**ì…ë‹ˆë‹¤.
- ì‚¬ìš©ìì˜ ì²´ì„±ë¶„ ì •ë³´(ì²´ì§€ë°©ë¥ , ê³¨ê²©ê·¼ëŸ‰, ìƒÂ·í•˜ì§€ ê·¼ìœ¡ ê· í˜• ë“±)ë¥¼ ë¶„ì„í•˜ì—¬ ê·¼ë ¥ìš´ë™ ë£¨í‹´ì„ ì¶”ì²œí•˜ì„¸ìš”.
- ì¶”ì²œì€ **3~5ê°œ ìš´ë™ìœ¼ë¡œ êµ¬ì„±ëœ ê°„ë‹¨í•œ ë£¨í‹´**ìœ¼ë¡œ ì œì‹œí•˜ê³ , ê° ìš´ë™ë§ˆë‹¤ **ì„¸íŠ¸ìˆ˜, ë°˜ë³µìˆ˜, ë¶€ìœ„, ë„êµ¬** ì •ë³´ë¥¼ í¬í•¨í•˜ì„¸ìš”.
- ë°˜ë“œì‹œ ì‚¬ìš©ìì˜ **ì²´í˜• ë¶ˆê· í˜• ë˜ëŠ” ëª©í‘œ(ê·¼ìœ¡ ì¦ê°€, ì²´ì§€ë°© ê°ëŸ‰ ë“±)**ì— ê·¼ê±°í•´ ìš´ë™ì„ ì œì•ˆí•˜ì„¸ìš”.
- ì¶”ì²œí•œ ìš´ë™ì˜ **ê³¼í•™ì  íƒ€ë‹¹ì„±**ì€ ë‚´ë¶€ì ìœ¼ë¡œ RAGë¡œ í•™ìŠµí•œ ë…¼ë¬¸ ê·¼ê±°ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•˜ì§€ë§Œ, ì‚¬ìš©ìëŠ” ë³µì¡í•œ ì—°êµ¬ ì„¤ëª…ë³´ë‹¤ëŠ” **ê°„ê²°í•œ ì´ìœ  ìš”ì•½**ë§Œ ì œê³µí•©ë‹ˆë‹¤.
- ë§íˆ¬ëŠ” **ì¹œì ˆí•˜ì§€ë§Œ ê°„ê²°í•˜ê²Œ**, ì‚¬ìš©ìê°€ íŠ¸ë ˆì´ë„ˆì—ê²Œ 1:1 ì§€ë„ë¥¼ ë°›ëŠ” ëŠë‚Œì„ ì¤˜ì•¼ í•©ë‹ˆë‹¤.
- ë¶ˆí•„ìš”í•œ ì¡ë‹´ì€ ì‚¼ê°€ê³ , **ì •í™•í•œ ìš´ë™ ì¶”ì²œ ì¤‘ì‹¬**ìœ¼ë¡œ ì‘ë‹µí•©ë‹ˆë‹¤. - ë‹¹ì‹ ì€ ìµœì‹  ìš´ë™ ìƒë¦¬í•™ ë…¼ë¬¸ ë° ì €í•­ì„± ìš´ë™ íš¨ê³¼ì— ëŒ€í•œ RAG ê¸°ë°˜ ì§€ì‹ì„ ê°–ê³  ìˆìŠµë‹ˆë‹¤.
- ê·¼ê±°ê°€ í•„ìš”í•œ ê²½ìš°, "ì´ ìš´ë™ì€ [ë…¼ë¬¸ ìš”ì•½ ê·¼ê±°]"ì™€ ê°™ì´ 1ë¬¸ì¥ ìš”ì•½ë§Œ ì œì‹œí•˜ì„¸ìš”.'''},
            {"role": "user", "content": prompt}
        ]
    )
    answer = chat_response.choices[0].message.content
    referenced_titles = [item["title"] for item in contexts_with_titles]
    return {"answer": answer, "titles": referenced_titles}

# âœ… ì‹¤í–‰ íë¦„ (í„°ë¯¸ë„ì—ì„œ ì‹¤í–‰ ì‹œ)
if __name__ == "__main__":
    query = input("â“ ìš´ë™ ê´€ë ¨ ì§ˆë¬¸ì„í•´ì£¼ì„¸ìš”: ")
    start_time = time.perf_counter()
    print("\nğŸ“¤ ì¿¼ë¦¬ ì „ì†¡ ì¤‘...")
    vector = get_query_embedding(query)

    if vector is not None:  # ì„ë² ë”©ì´ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆì„ ê²½ìš°ì—ë§Œ ê²€ìƒ‰ ì§„í–‰
        print("ğŸ” ìœ ì‚¬ ë¬¸ì„œ ê²€ìƒ‰ ì¤‘...")
        contexts_with_titles = search_similar_docs(vector)
        print(f"ğŸ“š ê²€ìƒ‰ëœ ë¬¸ì„œ ìˆ˜: {len(contexts_with_titles)}")

        print("ğŸ’¡ GPT ì‘ë‹µ ìƒì„± ì¤‘...")
        response_data = generate_response(query, contexts_with_titles)
        answer = response_data["answer"]
        titles = response_data["titles"]
        end_time = time.perf_counter()
        response_time = end_time - start_time

        print("\nğŸ’¬ GPT ì‘ë‹µ:\n", answer)
        if titles:
            print("\nğŸ“„ ë…¼ë¬¸ì„ ì°¸ê³ í•˜ì—¬ ë‹µë³€í•œ ë‚´ìš©:")
            for i, title in enumerate(set(titles)): # ì¤‘ë³µ ì œê±° í›„ ì¶œë ¥
                print(f"# {i+1}. {title}")
            print(f"\nâ³ ì‘ë‹µ ì†Œìš” ì‹œê°„: {response_time:.2f} ì´ˆ")

        else:
            print("\nğŸ“„ ë…¼ë¬¸ì„ ì°¸ê³ í•˜ì—¬ ë‹µë³€í•œ ë‚´ìš©: ì—†ìŒ")
            print(f"\nâ³ ì‘ë‹µ ì†Œìš” ì‹œê°„: {response_time:.2f} ì´ˆ")
    else:
        print("\nâš ï¸ ì„ë² ë”© ìƒì„±ì— ì‹¤íŒ¨í•˜ì—¬ ê²€ìƒ‰ì„ ì§„í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

def respond(query):
    start_time = time.perf_counter()
    print("\nğŸ“¤ ì¿¼ë¦¬ ì „ì†¡ ì¤‘...")
    vector = get_query_embedding(query)

    if vector is not None:
        print("ğŸ” ìœ ì‚¬ ë¬¸ì„œ ê²€ìƒ‰ ì¤‘...")
        contexts_with_titles = search_similar_docs(vector)
        num_references = len(contexts_with_titles)
        print(f"ğŸ“š ê²€ìƒ‰ëœ ë¬¸ì„œ ìˆ˜: {num_references}")

        print("ğŸ’¡ GPT ì‘ë‹µ ìƒì„± ì¤‘...")
        response_data = generate_response(query, contexts_with_titles)
        answer = response_data["answer"]
        titles = response_data["titles"]
        end_time = time.perf_counter()
        response_time = end_time - start_time

        response_string = f"{answer}\n\n"

        # ì£¼ì„ ê¸°ëŠ¥ (ì œëª©ë§Œ í¬í•¨)
        if titles:
            response_string += "ğŸ“„ ë…¼ë¬¸ì„ ì°¸ê³ í•˜ì—¬ ë‹µë³€í•œ ë‚´ìš©:\n"
            unique_titles = list(set(titles))
            for i, title in enumerate(unique_titles):
                response_string += f"# {i+1}. {title}\n"
        else:
            response_string += "ğŸ“„ ì°¸ê³  ë…¼ë¬¸: ì—†ìŒ\n"


        # ì‘ë‹µ ì†Œìš” ì‹œê°„ ì¶œë ¥
        response_string += f"â³ ì‘ë‹µ ì†Œìš” ì‹œê°„: {response_time:.2f} ì´ˆ"
        return response_string
    else:
        return "âš ï¸ ì„ë² ë”© ìƒì„±ì— ì‹¤íŒ¨í•˜ì—¬ ê²€ìƒ‰ì„ ì§„í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

iface = gr.Interface(
    fn=respond,
    inputs=gr.Textbox(label="ì§ˆë¬¸"),
    outputs=gr.Textbox(label="ë‹µë³€"),
    title="ì €í•­ì„± ìš´ë™ ì±—ë´‡"
)

iface.launch(share=True)